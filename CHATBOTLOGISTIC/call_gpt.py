import os
from openai import OpenAI
from langchain_core.runnables import RunnableLambda
from chatstate import ChatState
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def call_gpt(state: ChatState) -> ChatState:
    print("â–¶ [call_model_node] GPT Ä‘ang Ä‘Æ°á»£c gá»i Ä‘á»ƒ giáº£i thÃ­ch...")
    info = state.extracted_info or {}

    modes = state.shipment_mode if isinstance(state.shipment_mode, list) else [state.shipment_mode]
    label_probs = getattr(state, "label_probs", {})

    # Format cÃ¡c phÆ°Æ¡ng thá»©c Ä‘Æ°á»£c AI Ä‘á» xuáº¥t (thÃªm xÃ¡c suáº¥t náº¿u cÃ³)
    mode_lines = "\n".join(
    f"- {mode} ({round(label_probs[mode]*100, 1)}%)" if label_probs.get(mode) is not None else f"- {mode}"
    for mode in modes
)
    order_summary = f"""
QuÃ½ khÃ¡ch cáº§n gá»­i {info.get('weight')}kg linh kiá»‡n Ä‘iá»‡n tá»­ tá»« {info.get('origin_country')} Ä‘áº¿n {info.get('destination_country')}.
GiÃ¡ má»—i pack lÃ  {info.get('pack_price')} USD, phÃ­ váº­n chuyá»ƒn khoáº£ng {info.get('freight_cost')} USD.
Dá»± Ã¡n mÃ£ {info.get('project_code')} tá»« Ä‘á»‘i tÃ¡c {info.get('vendor')}, dá»± kiáº¿n gá»­i vÃ o ngÃ y {info.get('pq_date')}.
"""
    prompt = f"""
Báº¡n lÃ  má»™t chuyÃªn gia tÆ° váº¥n váº­n chuyá»ƒn thÃ´ng minh. DÆ°á»›i Ä‘Ã¢y lÃ  thÃ´ng tin Ä‘Æ¡n hÃ ng:

{order_summary}

Káº¿t quáº£ tá»« mÃ´ hÃ¬nh AI MAPIE: cÃ¡c phÆ°Æ¡ng thá»©c váº­n chuyá»ƒn Ä‘Æ°á»£c Ä‘á» xuáº¥t lÃ :
{mode_lines}

â—LÆ°u Ã½: ÄÃ¢y lÃ  toÃ n bá»™ káº¿t quáº£ tá»« AI, khÃ´ng Ä‘Æ°á»£c bá»‹a Ä‘áº·t hay phÃ¢n tÃ­ch phÆ°Æ¡ng thá»©c khÃ¡c.

YÃªu cáº§u:
1. PhÃ¢n tÃ­ch tá»«ng phÆ°Æ¡ng thá»©c nÃªu trÃªn, **liÃªn há»‡ trá»±c tiáº¿p vá»›i Ä‘Æ¡n hÃ ng nÃ y**, nÃªu rÃµ Æ°u Ä‘iá»ƒm vÃ  nhÆ°á»£c Ä‘iá»ƒm.
2. So sÃ¡nh cÃ¡c phÆ°Æ¡ng thá»©c náº¿u cÃ³ nhiá»u.
3. Gá»£i Ã½ lá»±a chá»n phÃ¹ há»£p nháº¥t tÃ¹y theo má»¥c tiÃªu (giao nhanh, tiáº¿t kiá»‡m chi phÃ­, an toÃ n).

TrÃ¬nh bÃ y chuyÃªn nghiá»‡p, ngáº¯n gá»n, dá»… hiá»ƒu.

TrÃ¢n trá»ng,
[ChuyÃªn viÃªn Logistic]
"""



    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
        max_tokens=1200,
        top_p=1.0
    )

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
        max_tokens=1200,
        top_p=1.0
    )

    # âœ… Pháº£n há»“i GPT chÃ­nh
    state.final_answer = response.choices[0].message.content.strip()

    # âœ… ThÃªm pháº§n support tiáº¿p theo
    state.final_answer += (
        "\n\nğŸ¤– QuÃ½ khÃ¡ch cÃ³ cáº§n tÃ´i há»— trá»£ thÃªm vá» giÃ¡ váº­n chuyá»ƒn, thá»i gian giao hÃ ng, "
        "quy trÃ¬nh thá»§ tá»¥c háº£i quan, hoáº·c thÃ´ng tin vá» nhÃ  cung cáº¥p khÃ´ng áº¡? "
        "Vui lÃ²ng nháº¯n tin Ä‘á»ƒ tiáº¿p tá»¥c tÆ° váº¥n."
    )
    state.support_mode = True
    state.support_count = 0
    return state
